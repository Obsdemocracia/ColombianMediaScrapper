{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eltiempo(url):\n",
    "    if \"opinion\" in url:\n",
    "        response = requests.get(url)\n",
    "        sopa= BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        \n",
    "        titulo=sopa.find_all(class_=\"title\")[0].get_text()\n",
    "        autor_categoria=sopa.find_all(class_=\"who\")\n",
    "\n",
    "        autor=autor_categoria[3].get_text()\n",
    "        categoria=autor_categoria[0].get_text()\n",
    "        \n",
    "        content=sopa.find_all(class_=\"contenido\")\n",
    "        contenido=\"\"\n",
    "        for i in content:\n",
    "            contenido+=\" \"\n",
    "            contenido+=(i.get_text())\n",
    "                \n",
    "        contenido=contenido.split(u'\\n\\n\\n\\n\\n\\n\\n')[0] \n",
    "        contenido=contenido.replace(u'\\n', u' ')\n",
    "        contenido=contenido.replace(u'\\xa0', u' ')\n",
    "        fecha=sopa.find_all(class_=\"publishedAt\")\n",
    "        fecha=fecha[2].get_text()\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        response = requests.get(url)\n",
    "        sopa= BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        titulo=sopa.find_all(class_=\"titulo\")[0].get_text()\n",
    "        \n",
    "        autor_categoria=sopa.find_all(class_=\"who\")\n",
    "        \n",
    "        autor=autor_categoria[3].get_text()\n",
    "        categoria=autor_categoria[0].get_text()\n",
    "        \n",
    "        content=sopa.find_all(class_=\"contenido\")\n",
    "        contenido=\"\"\n",
    "        for i in content:\n",
    "            contenido+=\" \"\n",
    "            contenido+=(i.get_text())\n",
    "        contenido=contenido.split(u'\\n\\n\\n\\n\\n\\n\\n')[0] \n",
    "        contenido=contenido.replace(u'\\n', u' ')\n",
    "        contenido=contenido.replace(u'\\xa0', u' ')\n",
    "        \n",
    "        fecha=sopa.find_all(class_=\"publishedAt\")\n",
    "        fecha=fecha[2].get_text()\n",
    "        \n",
    "    diccionario={\"titulo\":titulo,\"autor\":autor, \"fecha\":fecha,\"categoría\":categoria,\n",
    "                 \"contenido\":contenido,\"url\":url}\n",
    "    return diccionario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcnradio(url):\n",
    "    url=url.split(\".com\")[1]\n",
    "    url=\"https://www.rcnradio.com\" + url\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    sopa= BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    titulo=sopa.find(\"h1\")\n",
    "    titulo=titulo.get_text()\n",
    "    \n",
    "    autor=sopa.find(class_=\"name-author\")\n",
    "    autor=autor.get_text()\n",
    "    \n",
    "    fecha=sopa.find(class_=\"datetime\")\n",
    "    fecha=fecha.get_text()\n",
    "    \n",
    "    categoria=url.split(\"/\")[3]\n",
    "    \n",
    "    contenido=sopa.find_all(class_=\"item4\")\n",
    "    contenido=contenido[0].get_text()\n",
    "    \n",
    "    contenido=contenido.replace(u'\\n', u' ')\n",
    "    contenido=contenido.replace(u'\\xa0', u' ')\n",
    "    diccionario={\"titulo\":titulo,\"autor\":autor, \"fecha\":fecha,\"categoría\":categoria,\n",
    "             \"contenido\":contenido,\"url\":url}\n",
    "    return diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elnuevosiglo(url):\n",
    "    response = requests.get(url)\n",
    "    sopa= BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    titulo=sopa.find_all(class_=\"field field--name-title field--type-string field--label-hidden\")\n",
    "    titulo=titulo[0].get_text()\n",
    "    \n",
    "    autor_fecha=sopa.find_all(class_=\"info-line\")\n",
    "    \n",
    "    fecha=autor_fecha[-1].get_text()\n",
    "    autor=autor_fecha[0].get_text()\n",
    "    if autor==fecha: \n",
    "        autor=sopa.find_all(class_=\"username\")\n",
    "        autor=autor[0].get_text()\n",
    "   \n",
    "\n",
    "    contenido=sopa.find(class_=\"clearfix text-formatted field field--name-body field--type-text-with-summary field--label-hidden field__item\")\n",
    "    contenido=contenido.get_text()\n",
    "    \n",
    "    contenido=contenido.replace(u'\\n', u' ')\n",
    "    contenido=contenido.replace(u'\\xa0', u' ')\n",
    "    \n",
    "    diccionario={\"titulo\":titulo,\"autor\":autor, \"fecha\":fecha,\"categoría\":np.nan,\n",
    "                 \"contenido\":contenido,\"url\":url}\n",
    "    \n",
    "    return diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elpais(url):\n",
    "    response = requests.get(url)\n",
    "    sopa= BeautifulSoup(response.text, \"html.parser\")    \n",
    "    \n",
    "    titulo=sopa.find_all(class_=\"col-xs-12 article-title\")\n",
    "    titulo=titulo[0].get_text()\n",
    "    \n",
    "    fecha=sopa.find_all(class_=\"published-at\")\n",
    "    fecha=fecha[0].get_text()\n",
    "    \n",
    "    autor=sopa.find_all(class_=\"signature-container\")\n",
    "    autor=autor[0].get_text()\n",
    "    \n",
    "    categoria=url.split(\"/\")[3]\n",
    "    \n",
    "    content=sopa.find_all(class_=\"epigraph paragraph\")\n",
    "    contenido=\"\"\n",
    "    for i in range(len(content)):\n",
    "        contenido+=\" \"\n",
    "\n",
    "        cont=content[i].get_text()\n",
    "\n",
    "        contenido+=cont\n",
    "    \n",
    "    \n",
    "    contenido=contenido.replace(u'\\n', u' ')\n",
    "    contenido=contenido.replace(u'\\xa0', u' ')\n",
    "    diccionario={\"titulo\":titulo,\"autor\":autor, \"fecha\":fecha,\"categoría\":categoria,\n",
    "                 \"contenido\":contenido,\"url\":url}\n",
    "    \n",
    "    return diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wradio(url):\n",
    "    response = requests.get(url)\n",
    "    sopa= BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    titulo=sopa.find_all(\"h1\")\n",
    "    titulo=titulo[0].get_text()\n",
    "    \n",
    "    autor=sopa.find_all(class_=\"autor\")\n",
    "    autor=autor[-1].get_text()\n",
    "    \n",
    "    fecha=sopa.find_all(class_=\"actualizado posh\")\n",
    "    fecha=fecha[0].get_text()\n",
    "    fecha=fecha.split(\" -\")[0]\n",
    "    \n",
    "    \n",
    "    categoria=sopa.find(class_=\"titular\")\n",
    "    categoria=categoria.get_text()\n",
    "    \n",
    "    contenido=sopa.find_all(class_=\"cuerpo_noticia estirar\")\n",
    "\n",
    "\n",
    "    contenido=contenido[0].get_text()\n",
    "    contenido=contenido.split(\"Reciba desde Google\")[0]\n",
    "\n",
    "\n",
    "    contenido=contenido.replace(u'\\n', u' ')\n",
    "    contenido=contenido.replace(u'\\xa0', u' ')\n",
    "\n",
    "    diccionario={\"titulo\":titulo,\"autor\":autor, \"fecha\":fecha,\"categoría\":categoria,\n",
    "                 \"contenido\":contenido,\"url\":url}\n",
    "    \n",
    "    return diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diariomagdalena(url):\n",
    "    response = requests.get(url)\n",
    "    sopa= BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    titulo=sopa.find(itemprop=\"headline\")\n",
    "    titulo=titulo.get_text()\n",
    "    \n",
    "    autor=np.nan\n",
    "    \n",
    "    fecha=sopa.find(\"time\")\n",
    "    fecha=fecha.get_text()\n",
    "    try:\n",
    "        fecha=fecha.split(\"Última actualización \")[1]\n",
    "    except:\n",
    "        fecha=fecha.split(\"Publicado en \")[1]\n",
    "    \n",
    "    \n",
    "    categoria=sopa.find_all(class_=\"term-badges\")\n",
    "    categoria=categoria[0].get_text()\n",
    "    \n",
    "    \n",
    "    \n",
    "    contenido=sopa.find(class_=\"entry-content clearfix single-post-content\")\n",
    "    contenido=contenido.get_text()\n",
    "    contenido=contenido.split(\"\\n\\nID:\")[0]\n",
    "    contenido=contenido.replace(u'\\n', u' ')\n",
    "    contenido=contenido.replace(u'\\xa0', u' ')\n",
    "    contenido=contenido.split(\"Síguenos en Telegram\")[1]\n",
    "    \n",
    "    diccionario={\"titulo\":titulo,\"autor\":autor, \"fecha\":fecha,\"categoría\":categoria,\n",
    "             \"contenido\":contenido,\"url\":url}\n",
    "\n",
    "    return diccionario\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elvallenato(url):\n",
    "    response = requests.get(url)\n",
    "    sopa= BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    titulo=sopa.find(class_=\"entry-title post-title\")\n",
    "    titulo=titulo.get_text()\n",
    "    \n",
    "    fecha=sopa.find(class_=\"date updated\")\n",
    "    fecha=fecha.get_text()\n",
    "    \n",
    "    categoria=sopa.find(class_=\"meta-cat\")\n",
    "    categoria=categoria.get_text()\n",
    "    content=sopa.find_all(\"p\")\n",
    "    contenido=\"\"\n",
    "    for i in content[3:]:\n",
    "        contenido+=i.get_text()\n",
    "    contenido=contenido.split(\"Tu dirección de correo\")[0]\n",
    "    \n",
    "    contenido=contenido.replace(u'\\n', u' ')\n",
    "    contenido=contenido.replace(u'\\xa0', u' ')\n",
    "\n",
    "    \n",
    "    diccionario={\"titulo\":titulo,\"autor\":autor, \"fecha\":fecha,\"categoría\":categoria,\n",
    "         \"contenido\":contenido,\"url\":url}\n",
    "\n",
    "    return diccionario\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lanacion(url):\n",
    "    \n",
    "    \n",
    "    response = requests.get(url)\n",
    "    sopa= BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    \n",
    "    titulo=sopa.find(class_=\"entry-title penci-entry-title penci-title-center\")\n",
    "    titulo=titulo.get_text()\n",
    "    \n",
    "    fecha=sopa.find(class_=\"entry-meta-item penci-posted-on\")\n",
    "    fecha=fecha.get_text()\n",
    "    fecha=fecha.split(\",\")\n",
    "    fecha=fecha[0]+fecha[-1]\n",
    "    \n",
    "    autor=sopa.find(class_=\"author vcard\")\n",
    "    autor=autor.get_text()\n",
    "    \n",
    "    categoria=sopa.find_all(itemprop=\"name\")\n",
    "    categoria=categoria[1].get_text()\n",
    "    \n",
    "    content=sopa.find_all(class_=\"penci-entry-content entry-content\")\n",
    "    content=content[0].find_all(\"p\")\n",
    "    contenido=\"\"\n",
    "    for i in content:\n",
    "        contenido+=i.get_text()\n",
    "\n",
    "    diccionario={\"titulo\":titulo,\"autor\":autor, \"fecha\":fecha,\"categoría\":categoria,\n",
    "         \"contenido\":contenido,\"url\":url}\n",
    "\n",
    "    return diccionario"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
